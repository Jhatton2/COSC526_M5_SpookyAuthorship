{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ntherndon97/COSC526_M5_SpookyAuthorship/blob/main/M5.12_TeamAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage 0: Import Data and "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Unzip Files for CSV Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8De-RJtFojD",
        "outputId": "34098cc6-441c-47ff-a3ea-858600ce0cc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unzipping complete.\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "# Paths to the zip files\n",
        "test_zip_path = 'test.zip'      # Update this with the correct path if needed\n",
        "train_zip_path = 'train.zip'    # Update this with the correct path if needed\n",
        "\n",
        "# Unzip test.zip in the current directory\n",
        "with zipfile.ZipFile(test_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()  # Extract to the current working directory\n",
        "\n",
        "# Unzip train.zip in the current directory\n",
        "with zipfile.ZipFile(train_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()  # Extract to the current working directory\n",
        "\n",
        "print(\"Unzipping complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create PySpark Session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwlwBdECGmTk",
        "outputId": "d1bff1ff-bcdb-45e2-d865-aa43528cf52f"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spooky Author\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "csv_file_path = './test.csv'\n",
        "test_df = spark.read.csv(csv_file_path, header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read train.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spooky Author\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "csv_file_path = './train.csv'\n",
        "train_df = spark.read.csv(csv_file_path, header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring structure, size, and distribution of information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Null rows with null value in the training dataset:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find null rows with null values in the training dataset\n",
        "# Only including columns that are relevant to the analysis.\n",
        "print(\"Null rows with null value in the training dataset:\")\n",
        "train_df.filter(train_df.text.isNull() | train_df.author.isNull()).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 5 rows of the dataframe:\n",
            "+-------+--------------------+------+\n",
            "|     id|                text|author|\n",
            "+-------+--------------------+------+\n",
            "|id26305|This process, how...|   EAP|\n",
            "|id17569|It never once occ...|   HPL|\n",
            "|id11008|In his left hand ...|   EAP|\n",
            "|id27763|How lovely is spr...|   MWS|\n",
            "|id12958|Finding nothing e...|   HPL|\n",
            "+-------+--------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show the first 5 rows of the dataframe\n",
        "print(\"First 5 rows of the dataframe:\")\n",
        "train_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataframe Schema:\n",
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- author: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print the schema of the dataframe\n",
        "print(\"Dataframe Schema:\")\n",
        "train_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows in the dataframe: 19579\n",
            "Number of columns in the dataframe: 3\n"
          ]
        }
      ],
      "source": [
        "# Print the number of rows in the dataframe\n",
        "print(\"Number of rows in the dataframe: \" + str(train_df.count()))\n",
        "\n",
        "# Print the number of columns in the dataframe\n",
        "print(\"Number of columns in the dataframe: \" + str(len(train_df.columns)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Column names of the dataframe:\n",
            "['id', 'text', 'author']\n"
          ]
        }
      ],
      "source": [
        "# Print the column names of the dataframe\n",
        "print(\"Column names of the dataframe:\")\n",
        "print(train_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19579\n",
            "Number of unknown authors: 1532\n",
            "Percentage of unknown authors: 8%\n",
            "\n",
            "\n",
            "\n",
            "Number of Edgar Allan Poe (EAP) entries: 7044\n",
            "Percentage of Edgar Allan Poe (EAP) entries: 36%\n",
            "\n",
            "\n",
            "\n",
            "Number of HP Lovecraft (HPL) entries: 5451\n",
            "Percentage of HP Lovecraft (HPL) entries: 28%\n",
            "\n",
            "\n",
            "\n",
            "Number of Mary Shelley (MWS) entries: 5552\n",
            "Percentage of Mary Shelley (MWS) entries: 28%\n"
          ]
        }
      ],
      "source": [
        "# Show number of each author in the dataframe\n",
        "\n",
        "eap_author_count = train_df.filter(train_df.author == 'EAP').count()\n",
        "hpl_author_count = train_df.filter(train_df.author == 'HPL').count()\n",
        "mws_author_count = train_df.filter(train_df.author == 'MWS').count()\n",
        "\n",
        "# NOTE: We may want to consider removing the unknown authors from the dataset since\n",
        "# they do not provide any useful information for training a model. We need an author\n",
        "# to train the model to predict the author of the text.\n",
        "unknown_authors = train_df.filter(train_df.author != 'MWS')\n",
        "unknown_authors = unknown_authors.filter(unknown_authors.author != 'HPL')\n",
        "unknown_authors = unknown_authors.filter(unknown_authors.author != 'EAP')\n",
        "unknown_author_count = unknown_authors.count()\n",
        "\n",
        "total_author_count = train_df.count()\n",
        "\n",
        "print(total_author_count)\n",
        "\n",
        "print(\"Number of unknown authors: \" + str(unknown_author_count))\n",
        "print(\"Percentage of unknown authors: \" + str(round((unknown_author_count/total_author_count)*100)) + \"%\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "print(\"Number of Edgar Allan Poe (EAP) entries: \" + str(eap_author_count))\n",
        "print(\"Percentage of Edgar Allan Poe (EAP) entries: \" + str(round((eap_author_count/total_author_count)*100)) + \"%\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "print(\"Number of HP Lovecraft (HPL) entries: \" + str(hpl_author_count))\n",
        "print(\"Percentage of HP Lovecraft (HPL) entries: \" + str(round((hpl_author_count/total_author_count)*100)) + \"%\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "print(\"Number of Mary Shelley (MWS) entries: \" + str(mws_author_count))\n",
        "print(\"Percentage of Mary Shelley (MWS) entries: \" + str(round((mws_author_count/total_author_count)*100)) + \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 5 rows of the dataframe:\n",
            "+-------+--------------------+\n",
            "|     id|                text|\n",
            "+-------+--------------------+\n",
            "|id02310|Still, as I urged...|\n",
            "|id24541|If a fire wanted ...|\n",
            "|id00134|And when they had...|\n",
            "|id27757|While I was think...|\n",
            "|id04081|I am not sure to ...|\n",
            "+-------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show the first 5 rows of the dataframe\n",
        "print(\"First 5 rows of the dataframe:\")\n",
        "test_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataframe Schema:\n",
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print the schema of the dataframe\n",
        "print(\"Dataframe Schema:\")\n",
        "test_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows in the dataframe: 8392\n",
            "Number of columns in the dataframe: 2\n"
          ]
        }
      ],
      "source": [
        "# Print the number of rows in the dataframe\n",
        "print(\"Number of rows in the dataframe: \" + str(test_df.count()))\n",
        "\n",
        "# Print the number of columns in the dataframe\n",
        "print(\"Number of columns in the dataframe: \" + str(len(test_df.columns)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Column names of the dataframe:\n",
            "['id', 'text']\n"
          ]
        }
      ],
      "source": [
        "# Print the column names of the dataframe\n",
        "print(\"Column names of the dataframe:\")\n",
        "print(test_df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage 1: Data Preparation - Exploratory data analysis and text mining pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove the rows with unknown author values from the training dataset\n",
        "train_df_cleaned = train_df.filter(train_df.author == 'MWS')\n",
        "train_df_cleaned = train_df_cleaned.union(train_df.filter(train_df.author == 'HPL'))\n",
        "train_df_cleaned = train_df_cleaned.union(train_df.filter(train_df.author == 'EAP'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Add visuals here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 5 rows of the dataframe:\n",
            "+-------+--------------------+------+--------------------+--------------------+\n",
            "|     id|                text|author|              tokens|     tokens_filtered|\n",
            "+-------+--------------------+------+--------------------+--------------------+\n",
            "|id27763|How lovely is spr...|   MWS|[how, lovely, is,...|[lovely, spring, ...|\n",
            "|id22965|A youth passed in...|   MWS|[a, youth, passed...|[youth, passed, s...|\n",
            "|id00912|I confess that ne...|   MWS|[i, confess, that...|[confess, neither...|\n",
            "|id16737|\"He shall find th...|   MWS|[\"he, shall, find...|[\"he, shall, find...|\n",
            "|id12799|He had escaped me...|   MWS|[he, had, escaped...|[escaped, me,, mu...|\n",
            "+-------+--------------------+------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Text tokenization and stop word removal\n",
        "\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
        "new_text_column_name = \"tokens\"\n",
        "\n",
        "# Tokenize the text column\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=new_text_column_name)\n",
        "train_df_cleaned = tokenizer.transform(train_df_cleaned)\n",
        "\n",
        "# Remove stop words from the text column\n",
        "remover = StopWordsRemover(inputCol=new_text_column_name, outputCol=new_text_column_name + \"_filtered\")\n",
        "train_df_cleaned = remover.transform(train_df_cleaned)\n",
        "\n",
        "# Show the first 5 rows of the dataframe\n",
        "print(\"First 5 rows of the dataframe:\")\n",
        "train_df_cleaned.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage 2: Feature Extraction"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
